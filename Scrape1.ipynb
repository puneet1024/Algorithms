{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scrape1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/puneet1024/Algorithms/blob/master/Scrape1.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "2aWZaGkCATXD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import csv\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-fIoEsqZAXSC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#url of the page from which data is to be extracted\n",
        "urlpage = 'http://www.fasttrack.co.uk/league-tables/tech-track-100/league-table/'\n",
        "#store the html in 'page'\n",
        "page = urllib.request.urlopen(urlpage)\n",
        "#Parse using BeautifulSoup and store in 'soup'\n",
        "soup = BeautifulSoup(page,'html.parser')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mzzvy_VdXXMu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#find results within the table\n",
        "table = soup.find('table', attrs={'class':'tableSorter'})\n",
        "results = table.find_all('tr')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QXjUtcg6FhW6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#printing the number of rows in the data\n",
        "print('Number of rows', len(results))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J6gmdBN-FqvB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zULuZa5nF2tk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QAdDSlObF5bz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create and write headers to a list\n",
        "rows = []\n",
        "rows.append(['Rank', 'Company Name', 'Webpage', 'Description', 'Location', 'Year end', 'Annual sales rise over 3 years', 'Sales', 'Staff', 'Comments'])\n",
        "print(rows)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tEQQb4qWGaov",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#loop through the results\n",
        "for result in results:\n",
        "  data = result.find_all('td')\n",
        "  if(len(data) == 0):\n",
        "    continue\n",
        "  #write columns to variables\n",
        "  rank = data[0].getText()\n",
        "  company = data[1].getText()\n",
        "  location = data[2].getText()\n",
        "  year_end = data[3].getText()\n",
        "  annual_rise= data[4].getText()\n",
        "  sales = data[5].getText()\n",
        "  staff = data[6].getText()\n",
        "  comments = data[7].getText()\n",
        "  company_name = data[1].find('span',attrs={'class':'company-name'}).getText()\n",
        "  description = company.replace(company_name,'')\n",
        "  sales = sales.strip('*').strip('â€ ').replace(',','')\n",
        "  #web url extraction \n",
        "  url = data[1].find('a').get('href')\n",
        "  page1 = urllib.request.urlopen(url)\n",
        "  soup1 = BeautifulSoup(page1,'html.parser')\n",
        "  try:\n",
        "    dat = soup1.find('table').find_all('tr')[-1]\n",
        "    webpage = dat.find('a').get('href')\n",
        "  except:\n",
        "    webpage = None\n",
        "  rows.append([rank, company_name, webpage, description, location, year_end, annual_rise, sales, staff, comments])\n",
        "with open('fastrac.csv','w',newline='') as f_output:\n",
        "  csv_output = csv.writer(f_output)\n",
        "  csv_output.writerows(rows)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JZAZpQScTT_9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('fastrac.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nXawNHBUTczj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}